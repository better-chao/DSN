在tensorflow中中每一层都可以指定正则化项，但是在pytorch中仅仅是在优化器中统一指定

pytorch 的torchvision.transforms.functional.py中to_tensor()的作用有两个
从to_tensor()函数源码看出其接受PIL Image或numpy.ndarray格式，功能如下：
先由HWC转置为CHW格式；
再转为float类型；
最后，每个像素除以255。

transforms.Normalize(norm_mean, norm_std)这个一般是在to tensor之后进行操作

模型正常刚训练之后发现的问题：
1.就是域无关的特征与域相关的特征之间的差异值在初始化随机参数之后，他们就非常小，也就是这个损失本来就很小，基本上是不需要优化，这主要
的原因在于采用两个编码器直接对一张图片进行编码，很难学习到真正的域相关或域无关的特征，也就是相当于在高维空间进行采样两个高维向量，他们
之间正交的可能性几乎是100%，这也就是原来网络设计的相当不合理的地方。也就是两个域之间的差异几乎上是没有的。

这一点可以作为重点改进的手段

如果这一块不起作用的话，其实dsn理论上和dann这个网络在效果上基本上是没有啥区别的

代码已经调试完成，但是有一个问题就是读取数据的效率太低，这已经成为了限制整个网络训练速度的瓶颈
也就是现在要解决的问题是，网络数据读取的速度太慢的问题

运行较慢的问题已经解决，主要是读取数据的代码写的有问题，但是现在遇到的精度太低的问题，现在目测是因为数据集的生成有问题
已经排除是数据的问题，结果证明数据的生成和数据的标签都是一一对应的，都是正确的，没有问题，所以现在就是观察是不是神经网络的问题，
因为经过观察发现那个dann的loss始终降不下去-->这个已经解决

